





data = 'https://raw.githubusercontent.com/alexeygrigorev/mlbookcamp-code/master/chapter-02-car-price/data.csv'


get_ipython().getoutput("wget $data")


import pandas as pd
import numpy as np


df = pd.read_csv('data.csv')
df.head()





# let's clean column names
df.columns = df.columns.str.lower().str.replace(' ', '_')
df.head()


# chose all columns that contains strings
strings = list(df.dtypes[df.dtypes == 'object'].index)
strings


# clean data in the same way how we did it with columns
for col in strings:
    df[col] = df[col].str.lower().str.replace(' ', '_')
df.head()





for col in df.columns:
    print(col)
    print(df[col].unique()[:5])
    print(df[col].nunique())


# distribution of price
import matplotlib.pyplot as plt
import seaborn as sns


sns.histplot(df.msrp, bins=50)


# let's look at car's price lower than 100k
sns.histplot(df.msrp[df.msrp < 100000], bins=50)


# let's get rid of long tail distribution
np.log([1, 10, 1000, 10000, 100000])


np.log([0 + 1, 1 + 1, 10 + 1, 1000 + 1, 10000 + 1, 100000 + 1])


np.log1p([0, 1, 10, 1000, 10000, 100000])


price_logs = np.log1p(df.msrp)
sns.histplot(price_logs, bins=50)


# missing values
df.isnull().sum()





n = len(df)
n_val = int(n*0.2)
n_test = int(n*0.2)
n_train = n - n_val - n_test
n, n_val, n_test, n_train


# let's shuffle index, so we will have different data in different sets
idx = np.arange(n)
np.random.seed(2)
np.random.shuffle(idx)


df_train = df.iloc[idx[:n_train]]
df_val = df.iloc[idx[n_train:n_train+n_val]]
df_test = df.iloc[idx[n_train+n_val:]]


df_train.head()


len(df_val), len(df_test), len(df_train)


df_train = df_train.reset_index(drop=True)
df_val = df_val.reset_index(drop=True)
df_test = df_test.reset_index(drop=True)


y_train = np.log1p(df_train.msrp.values)
y_val = np.log1p(df_val.msrp.values)
y_test = np.log1p(df_test.msrp.values)


del df_train['msrp']
del df_val['msrp']
del df_test['msrp']


len(df_val), len(df_test), len(df_train)


len(y_val), len(y_test), len(y_train)


df_train.columns





df_train.iloc[10]


# let's take engine_hp, city_mpg and popularity as a feature vector
xi = [453, 11, 86]

def g(xi):
    # TODO: implement
    # do something
    return 10000

g(xi)


# g(xi) = w0 + w1*xi1 + w2*xi2 + w3*xi3
# g(xi) = w0 + w*xi


w0 = 7.17
w = [0.01, 0.04, 0.002]
def linear_regression(xi):
    n = len(xi)
    pred = w0
    for j in range(n):
        pred += w[j] * xi[j]
    return pred


linear_regression(xi)


print(np.expm1(linear_regression(xi)))





def dot(xi, w):
    res = 0
    for j in range(len(xi)):
        res += xi[j]*w[j]
    return res


def linear_regression(xi):
    return w0 + dot(xi, w)


linear_regression(xi)


w_new = [w0] + w


def linear_regression(xi):
    xi = [1] + xi
    return dot(xi, w_new)


linear_regression(xi)





X = [
    [148, 24, 1385],
    [132, 25, 2031],
    [453, 11, 86],
    [158, 24, 185],
    [172, 25, 201],
    [413, 11, 86],
    [38,  54, 185],
    [142, 25, 431],
    [453, 31, 86],
]
X = np.array(X)
X


ones = np.ones(X.shape[0])
ones


X = np.column_stack([ones, X])


y = [100, 200, 150, 250, 100, 200, 150, 250, 120]


XTX = X.T.dot(X)


XTX_inv = np.linalg.inv(XTX)


w_full = XTX_inv.dot(X.T).dot(y)


w_full


w0, w = w_full[0], w_full[1:]
w0, w


def train_linear_regression(X, y):
    ones = np.ones(X.shape[0])
    X = np.column_stack([ones, X])
    XTX = X.T.dot(X)
    XTX_inv = np.linalg.inv(XTX)
    w_full = XTX_inv.dot(X.T).dot(y)
    return w_full[0], w_full[1:]


X = [
    [148, 24, 1385],
    [132, 25, 2031],
    [453, 11, 86],
    [158, 24, 185],
    [172, 25, 201],
    [413, 11, 86],
    [38,  54, 185],
    [142, 25, 431],
    [453, 31, 86],
]
X = np.array(X)
y = [100, 200, 150, 250, 100, 200, 150, 250, 120]

train_linear_regression(X, y)





df_train.columns


base = ['engine_hp', 'engine_cylinders', 'highway_mpg',
        'city_mpg', 'popularity',]
X_train = df_train[base].fillna(0).values


w0, w = train_linear_regression(X_train, y_train)


y_pred = w0 + X_train.dot(w)


sns.histplot(y_pred, color='red', alpha=0.5, bins=50)
sns.histplot(y_train, color='green', alpha=0.5, bins=50)





def rmse(y, y_pred):
    squared_error = (y - y_pred) ** 2
    mean_suqared_error = squared_error.mean()
    return np.sqrt(mean_suqared_error)


rmse(y_train, y_pred)





def prepare_X(df):
    base = ['engine_hp', 'engine_cylinders', 'highway_mpg',
        'city_mpg', 'popularity',]
    df_num = df[base]
    df_num = df_num.fillna(0)
    X = df_num.values
    return X


X_train = prepare_X(df_train)
w0, w = train_linear_regression(X_train, y_train)

X_val = prepare_X(df_val)
y_pred = w0 + X_val.dot(w)

rmse(y_val, y_pred)





def prepare_X(df):
    base = ['engine_hp', 'engine_cylinders', 'highway_mpg',
        'city_mpg', 'popularity',]
    features = base + ['age']
    df = df.copy()
    df['age'] = 2017 - df.year
    df_num = df[features]
    df_num = df_num.fillna(0)
    X = df_num.values
    return X


X_train = prepare_X(df_train)
w0, w = train_linear_regression(X_train, y_train)

X_val = prepare_X(df_val)
y_pred = w0 + X_val.dot(w)

rmse(y_val, y_pred)


sns.histplot(y_pred, color='red', alpha=0.5, bins=50)
sns.histplot(y_val, color='green', alpha=0.5, bins=50)





df_train.dtypes


# let's add feature num_doors_n
(df_train.number_of_doors == 4).astype('int')


def prepare_X(df):
    base = ['engine_hp',
            'engine_cylinders',
            'highway_mpg',
            'city_mpg',
            'popularity',]
    features = base.copy()
    df = df.copy()
    # age column
    df['age'] = 2017 - df.year
    features.append('age')
    # num_doors_n columns
    for v in [2, 3, 4]:
        column = f'num_doors_{v}'
        df[column] = (df.number_of_doors == v).astype('int')
        features.append(column)
    # take values
    print(features)
    df_num = df[features]
    df_num = df_num.fillna(0)
    X = df_num.values
    return X


X_train = prepare_X(df_train)
w0, w = train_linear_regression(X_train, y_train)

X_val = prepare_X(df_val)
y_pred = w0 + X_val.dot(w)

rmse(y_val, y_pred)


# let's take a look on 'make' column
df.make.nunique()


def prepare_X(df):
    base = ['engine_hp',
            'engine_cylinders',
            'highway_mpg',
            'city_mpg',
            'popularity',]
    features = base.copy()
    df = df.copy()
    # age column
    df['age'] = 2017 - df.year
    features.append('age')
    # num_doors_n columns
    for v in [2, 3, 4]:
        column = f'num_doors_{v}'
        df[column] = (df.number_of_doors == v).astype('int')
        features.append(column)
    # make columns
    makes = list(df.make.value_counts().head().index)
    for v in makes:
        column = f'make_{v}'
        df[column] = (df.make == v).astype('int')
        features.append(column)
    # take values
    print(features)
    df_num = df[features]
    df_num = df_num.fillna(0)
    X = df_num.values
    return X


X_train = prepare_X(df_train)
w0, w = train_linear_regression(X_train, y_train)

X_val = prepare_X(df_val)
y_pred = w0 + X_val.dot(w)

rmse(y_val, y_pred)


df_train.dtypes


def prepare_X(df):
    base = ['engine_hp',
            'engine_cylinders',
            'highway_mpg',
            'city_mpg',
            'popularity',]
    features = base.copy()
    df = df.copy()
    # age column
    df['age'] = 2017 - df.year
    features.append('age')
    # num_doors_n columns
    for v in [2, 3, 4]:
        column = f'num_doors_{v}'
        df[column] = (df.number_of_doors == v).astype('int')
        features.append(column)
    # categorical variables
    categorical_variables = [
        'make', 'transmission_type', 'driven_wheels',
        'market_category', 'vehicle_size', 'vehicle_style',
    ]
    for c in categorical_variables:
        categories = list(df[c].value_counts().head().index)
        for v in categories:
            column = f'{c}_{v}'
            df[column] = (df[c] == v).astype('int')
            features.append(column)
    # take values
    print(features)
    df_num = df[features]
    df_num = df_num.fillna(0)
    X = df_num.values
    return X


X_train = prepare_X(df_train)
w0, w = train_linear_regression(X_train, y_train)

X_val = prepare_X(df_val)
y_pred = w0 + X_val.dot(w)

rmse(y_val, y_pred)





def train_linear_regression_reg(X, y, r=0.001):
    ones = np.ones(X.shape[0])
    X = np.column_stack([ones, X])
    XTX = X.T.dot(X)
    XTX = XTX + r * np.eye(XTX.shape[0])
    XTX_inv = np.linalg.inv(XTX)
    w_full = XTX_inv.dot(X.T).dot(y)
    return w_full[0], w_full[1:]


X_train = prepare_X(df_train)
w0, w = train_linear_regression_reg(X_train, y_train, r=0.0001)

X_val = prepare_X(df_val)
y_pred = w0 + X_val.dot(w)

rmse(y_val, y_pred)





for r in [0.0, 10, 1, 0.1, 0.01, 0.001, 0.0001, 0.00001]:
    X_train = prepare_X(df_train)
    w0, w = train_linear_regression_reg(X_train, y_train, r)
    X_val = prepare_X(df_val)
    y_pred = w0 + X_val.dot(w)
    score = rmse(y_val, y_pred)
    print(r, w0, score)


r = 0.0001
X_train = prepare_X(df_train)
w0, w = train_linear_regression_reg(X_train, y_train, r)
X_val = prepare_X(df_val)
y_pred = w0 + X_val.dot(w)
rmse(y_val, y_pred)





df_full_train = pd.concat([df_train, df_val])
df_full_train = df_full_train.reset_index(drop=True)


y_full_train = np.concatenate([y_train, y_val])


r = 0.0001
X_full_train = prepare_X(df_full_train)
w0, w = train_linear_regression_reg(X_full_train, y_full_train, r)
X_test = prepare_X(df_test)
y_pred = w0 + X_test.dot(w)
rmse(y_test, y_pred)


categorical_variables = [
    'make', 'transmission_type', 'driven_wheels',
    'market_category', 'vehicle_size', 'vehicle_style',
]
categories = {}
for c in categorical_variables:
    categories[c] = list(df[c].value_counts().head().index)


def prepare_X(df):
    base = ['engine_hp',
            'engine_cylinders',
            'highway_mpg',
            'city_mpg',
            'popularity',]
    features = base.copy()
    df = df.copy()
    # age column
    df['age'] = 2017 - df.year
    features.append('age')
    # num_doors_n columns
    for v in [2, 3, 4]:
        column = f'num_doors_{v}'
        df[column] = (df.number_of_doors == v).astype('int')
        features.append(column)
    # categorical variables
    for c, cats in categories.items():
        for v in cats:
            column = f'{c}_{v}'
            df[column] = (df[c] == v).astype('int')
            features.append(column)
    # take values
    print(features)
    df_num = df[features]
    df_num = df_num.fillna(0)
    X = df_num.values
    return X


car = df_test.iloc[20].to_dict()
car


df_small = pd.DataFrame([car])
df_small


X_small = prepare_X(df_small)
X_small


y_pred = w0 + X_small.dot(w)
y_pred = y_pred[0]


np.expm1(y_pred)  # predicted price


np.expm1(y_test[20])  # real price



